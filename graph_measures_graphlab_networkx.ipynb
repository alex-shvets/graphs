{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## graph measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scipy.sparse.csgraph\n",
    "import graphlab\n",
    "from graphlab import SGraph\n",
    "graphlab.canvas.set_target('ipynb')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import itertools\n",
    "\n",
    "def get_graph_measures(mgraph):\n",
    "    summary = {}\n",
    "    suppl = {}\n",
    "    summary[\"num_nodes\"] = int(len(mgraph.vertices))\n",
    "\n",
    "    def in_degree(graph, top_num):\n",
    "        dgcount = graphlab.degree_counting.create(graph)\n",
    "        dgc_vert = dgcount['graph'].vertices.sort(\"in_degree\", False)\n",
    "        top_set = dgc_vert[\"__id\"][0:top_num]\n",
    "        return dgcount, top_set\n",
    "\n",
    "    dgcount, top_set_dg = in_degree(mgraph, top_num = 50)\n",
    "\n",
    "    def convert_graphlab_to_nx(graph, di):\n",
    "        nxgraph = nx.DiGraph() if di else nx.Graph()\n",
    "        nxgraph.add_nodes_from(list(graph.vertices['__id']))\n",
    "        nxgraph.add_edges_from([(e['__src_id'], e['__dst_id']) for e in graph.edges])\n",
    "        return nxgraph\n",
    "\n",
    "    nxmgraph = convert_graphlab_to_nx(mgraph, di=False)\n",
    "    nxdeg = nxmgraph.degree()\n",
    "\n",
    "    summary[\"in_degree_avg\"] = 1.0*sum(dgcount[\"graph\"].vertices[\"in_degree\"])/len(dgcount[\"graph\"].vertices)       \n",
    "    summary[\"in_degree_max\"] = max(dgcount[\"graph\"].vertices[\"in_degree\"])        \n",
    "    summary[\"degree_avg_undirected\"] = 1.0*sum(nxdeg.values())/len(nxdeg)\n",
    "    summary[\"degree_max_undirected\"] = max(nxdeg.values())\n",
    "    suppl[\"top_in_degree\"] = top_set_dg\n",
    "    \n",
    "    def pagerank(graph, top_num):\n",
    "        pr = graphlab.pagerank.create(graph)\n",
    "        pr_sort = pr['pagerank'].sort(\"pagerank\", False)\n",
    "        top_set = pr_sort[\"__id\"][0:top_num]\n",
    "        return pr, top_set\n",
    "\n",
    "    prank, top_pagerank = pagerank(mgraph, top_num = 100)\n",
    "    suppl[\"top_pagerank\"] = top_pagerank\n",
    "\n",
    "    gcolor = graphlab.graph_coloring.create(mgraph)\n",
    "    summary[\"upper_bound_num_colors_shares\"] = gcolor.num_colors\n",
    "\n",
    "    def connected_components(graph, visualisation = False):\n",
    "        cc = graphlab.connected_components.create(graph)\n",
    "        cc_sort = cc.component_size.sort(\"Count\", False)\n",
    "        #print(cc.summary())\n",
    "        if(visualisation):\n",
    "            cc_grouped = cc_sort.groupby(\"Count\", {\"total\" : graphlab.aggregate.COUNT})\n",
    "            cc_grouped = cc_grouped.sort(\"Count\")\n",
    "            y_pos = range(cc_grouped.num_rows())\n",
    "            plt.barh(y_pos, cc_grouped[\"total\"], align='center', alpha=0.8)\n",
    "            plt.yticks(y_pos, cc_grouped[\"Count\"])\n",
    "            plt.xlabel(\"number of components\")\n",
    "            plt.title(\"number of components of each size\")\n",
    "            plt.show()\n",
    "        max_component_size = cc_sort[\"Count\"][0]\n",
    "        graph.vertices['component_id'] = cc['graph'].vertices['component_id']\n",
    "        targets = cc[\"graph\"].get_vertices(fields={\"component_id\":cc_sort[\"component_id\"][0]})[\"__id\"]\n",
    "        max_component = graph.get_neighborhood(ids=targets, radius=1, full_subgraph=True)\n",
    "        return cc, max_component, max_component_size\n",
    "\n",
    "    cc, max_cc, max_cc_size = connected_components(mgraph, visualisation = True)\n",
    "    suppl[\"max_cc\"] = max_cc\n",
    "    summary[\"max_cc_size\"] = max_cc_size\n",
    "    summary[\"max_cc_relative_size\"] = 1.0*max_cc_size/mgraph.summary()['num_vertices']\n",
    "\n",
    "    tc = graphlab.triangle_counting.create(max_cc)\n",
    "    tc_num = tc['num_triangles']\n",
    "    tcount = tc['triangle_count']\n",
    "    #print(tc_num)\n",
    "    #tcount = tcount.sort('triangle_count', False)\n",
    "    #print(tcount[\"triangle_count\"][0]) - maximal number of triangles for a node\n",
    "    tcount_not_in_triangles = tcount.filter_by(0, \"triangle_count\")\n",
    "    summary[\"num_triangles_in_max_cc\"] = tc_num\n",
    "    summary[\"relnum_nodes_form_triangles_in_cc\"] = tcount.num_rows() - tcount_not_in_triangles.num_rows()\n",
    "\n",
    "    def k_core(graph):\n",
    "        kc = graphlab.kcore.create(graph,0,1000)\n",
    "        kcore_id = kc['core_id']\n",
    "        max_k = max(kcore_id[\"core_id\"])\n",
    "        kcore_id[\"max\"] = [True if (kcore_id[\"core_id\"][i] == max_k) else False for i in xrange(kcore_id.num_rows())]\n",
    "        kcore_id = kcore_id.filter_by(True, \"max\")\n",
    "        return max_k, kcore_id.num_rows()\n",
    "\n",
    "    max_k, max_core_size = k_core(mgraph)\n",
    "    summary[\"num_cores\"] = max_k\n",
    "    summary[\"rel_max_core_size\"] = 1.0*max_core_size/max_cc_size\n",
    "\n",
    "    nx_max_cc = convert_graphlab_to_nx(max_cc, di=False)\n",
    "    avg_clust = nx.average_clustering(nx_max_cc)\n",
    "    summary[\"avg_clust_coef\"] = avg_clust\n",
    "\n",
    "    return summary, suppl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"\"\n",
    "mgraph = graphlab.load_sgraph(path)\n",
    "summary, suppl = get_graph_measures(mgraph)\n",
    "for v in summary:\n",
    "    summary[v] = [summary[v]]\n",
    "sf = graphlab.SFrame(summary)\n",
    "sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine with Networkit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import graphlab\n",
    "from graphlab import SGraph\n",
    "graphlab.canvas.set_target('ipynb')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "summary_name = \"summary_main\"\n",
    "summ_ntwk = \"summary_networkit.pckl\"\n",
    "save_name = \"small_cities_graph_measures\"\n",
    "\n",
    "sf_main = graphlab.load_sframe(summary_name)\n",
    "#cities = list(line.strip() for line in (open(\"protest_small_cities_unique_names_ids.lst\", \"r\")))\n",
    "#sf_main[\"protest\"] = [1 if (str(sf_main[\"city_id\"][i]) in cities) else 0 for i in xrange(sf_main.num_rows())]\n",
    "#sf_main.save(summary_name)\n",
    "df_main = pd.read_pickle(summ_ntwk)\n",
    "\n",
    "df_main[\"city_id\"] = df_main[\"city_id\"].astype(int)\n",
    "sf_main1 = graphlab.SFrame(data=df_main)\n",
    "sf_main = sf_main.join(sf_main1, how = \"inner\")\n",
    "sf_main = sf_main.sort([(\"protest\", False),(\"city_id\", True)])\n",
    "sf_main.save(save_name)\n",
    "df_main = sf_main.to_dataframe()\n",
    "cols = ['protest','city_id','city_name','city_pop_stata','num_nodes_in_common','num_nodes_in_comments','num_nodes_in_likes','num_nodes_in_shares','diameter','eff_diameter','in_degree_avg_common','in_degree_avg_comments','in_degree_avg_likes','in_degree_avg_shares','in_degree_max_common','in_degree_max_comments','in_degree_max_likes','in_degree_max_shares','degree_avg_undirected_common','degree_avg_undirected_comments','degree_avg_undirected_likes','degree_avg_undirected_shares','degree_max_undirected_common','degree_max_undirected_comments','degree_max_undirected_likes','degree_max_undirected_shares','num_nodes_from_top100_indegree_in_each_collection','max_cc_size_common','max_cc_size_comments','max_cc_size_likes','max_cc_size_shares','max_cc_relative_size_common','max_cc_relative_size_comments','max_cc_relative_size_likes','max_cc_relative_size_shares','num_triangles_in_max_cc_common','num_triangles_in_max_cc_comments','num_triangles_in_max_cc_likes','num_triangles_in_max_cc_shares','relnum_nodes_form_triangles_in_cc_common','relnum_nodes_form_triangles_in_cc_comments','relnum_nodes_form_triangles_in_cc_likes','relnum_nodes_form_triangles_in_cc_shares','avg_clust_coef_common','avg_clust_coef_comments','avg_clust_coef_likes','avg_clust_coef_shares','num_cores_common','num_cores_comments','num_cores_likes','num_cores_shares','rel_max_core_size_common','rel_max_core_size_comments','rel_max_core_size_likes','rel_max_core_size_shares','communities_num','communities_avg_size','communities_max_size','communities_rel_avg_size','communities_rel_max_size','communities_modularity','upper_bound_num_colors_common','upper_bound_num_colors_comments','upper_bound_num_colors_likes','upper_bound_num_colors_shares','avg_btwc','avg_degc','avg_eigc','max_btwc','max_degc','max_eigc','num_nodes_high_btwc','num_nodes_high_degc','num_nodes_high_eigc','rel_num_nodes_high_btwc','rel_num_nodes_high_degc','rel_num_nodes_high_eigc','num_nodes_from_top100_pagerank_in_each_collection']\n",
    "df_main = df_main[cols]\n",
    "df_main.to_csv(save_name+'.csv',index=False)\n",
    "df_main.to_excel(save_name+'.xls',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    upfolder_cmn_and_ccs = \"common_graphs_and_max_ccs\"\n",
    "    upfolder = \"ready_sframes_sgraphs\"\n",
    "    period = \"\"\n",
    "    summary_name = \"summary_main\"\n",
    "\n",
    "    sf_main = graphlab.SFrame()\n",
    "    if os.path.exists(summary_name):\n",
    "        sf_main = graphlab.load_sframe(summary_name)\n",
    "\n",
    "    cities_prot = list(line.strip() for line in (open(\"protest_small_cities_unique_names_ids.lst\", \"r\")))\n",
    "    cities_non_prot_w = list(line.strip() for line in (open(\"nonprotest_small_cities_unique_names_weather_ids.lst\", \"r\")))\n",
    "    cities_non_prot_nonw = [\"54\"]\n",
    "    cities = list(itertools.chain(cities_prot, cities_non_prot_w, cities_non_prot_nonw))\n",
    "    \n",
    "    sm_cities = pd.read_stata(\"cities below 100 with population.dta\")\n",
    "    sm_cities[\"id\"] = sm_cities[\"id\"].astype(int)\n",
    "    sm_cities[\"id_index\"] = sm_cities[\"id\"].apply(lambda x:x)\n",
    "    sm_cities = sm_cities.set_index('id_index')\n",
    "    for city in cities:\n",
    "        try:\n",
    "            print(str(city))\n",
    "            \n",
    "            if(\"city_id\" in sf_main.column_names())and(summary[\"city_id\"] in list(sf_main[\"city_id\"])):\n",
    "                print(str(city), \"city has already been done\")\n",
    "                continue\n",
    "            city_str = str(city)\n",
    "            print(\"analysis of the city %s\" % city_str)          \n",
    "            \n",
    "            gshares = graphlab.load_sgraph(upfolder+\"\\\\shares_\"+period+\"sgraph_city_\"+city_str)\n",
    "            glikes = graphlab.load_sgraph(upfolder+\"\\\\likes_\"+period+\"sgraph_city_\"+city_str)\n",
    "            gcomments = graphlab.load_sgraph(upfolder+\"\\\\comments_\"+period+\"sgraph_city_\"+city_str)\n",
    "            fshares = graphlab.load_sframe(upfolder+\"\\\\shares_\"+period+\"sframe_city_\"+city_str)\n",
    "            flikes = graphlab.load_sframe(upfolder+\"\\\\likes_\"+period+\"sframe_city_\"+city_str)\n",
    "            fcomments = graphlab.load_sframe(upfolder+\"\\\\comments_\"+period+\"sframe_city_\"+city_str)\n",
    "            print(str(city), )\n",
    "            fshares.rename({\"owner_id\":\"from_id\", \"copy_history_owner_id\":\"to_id\"})\n",
    "            flikes.rename({\"from_id\":\"from_id\", \"object_owner_id\":\"to_id\"})\n",
    "            fcomments.rename({\"from_id\":\"from_id\", \"object_owner_id\":\"to_id\"})\n",
    "\n",
    "            fcommon = graphlab.SFrame()\n",
    "            fcommon = fcommon.append(fshares)\n",
    "            fcommon = fcommon.append(flikes)\n",
    "            fcommon = fcommon.append(fcomments)\n",
    "\n",
    "            fcommon = fcommon.groupby([\"to_id\", \"from_id\"], {\"total\":graphlab.aggregate.SUM(\"total\")})\n",
    "\n",
    "            gcommon = SGraph()\n",
    "            gcommon = gcommon.add_edges(fcommon, src_field=\"from_id\", dst_field=\"to_id\")\n",
    "            fcommon.save(upfolder_cmn_and_ccs+\"\\\\common_sframe_\"+period+(\"city_%s\" % city_str))\n",
    "            gcommon.save(upfolder_cmn_and_ccs+\"\\\\common_sgraph_\"+period+(\"city_%s\" % city_str))\n",
    "\n",
    "            print(gshares)\n",
    "            print(glikes)\n",
    "            print(gcomments)\n",
    "            print(gcommon)\n",
    "            \n",
    "            summary = {}\n",
    "            suppl = {}\n",
    "            summary[\"protest\"] = (str(city) in cities_prot) or (int(city) in cities_prot)\n",
    "            summary[\"city_id\"] = int(city)\n",
    "            summary[\"city_name\"] = sm_cities.get_value(int(city), \"city_name_eng\")\n",
    "            summary[\"city_pop_stata\"] = sm_cities.get_value(int(city), \"pop\")\n",
    "            summary_temp, suppl_temp = get_graph_measures(gshares)\n",
    "            for dkey in summary_temp:\n",
    "                summary[dkey+\"_shares\"] = summary_temp[dkey]\n",
    "            for dkey in suppl_temp:\n",
    "                suppl[dkey+\"_shares\"] = suppl_temp[dkey]\n",
    "            del summary_temp\n",
    "            del suppl_temp\n",
    "            summary_temp, suppl_temp = get_graph_measures(glikes)\n",
    "            for dkey in summary_temp:\n",
    "                summary[dkey+\"_likes\"] = summary_temp[dkey]\n",
    "            for dkey in suppl_temp:\n",
    "                suppl[dkey+\"_likes\"] = suppl_temp[dkey]\n",
    "            del summary_temp\n",
    "            del suppl_temp\n",
    "            summary_temp, suppl_temp = get_graph_measures(gcomments)\n",
    "            for dkey in summary_temp:\n",
    "                summary[dkey+\"_comments\"] = summary_temp[dkey]\n",
    "            for dkey in suppl_temp:\n",
    "                suppl[dkey+\"_comments\"] = suppl_temp[dkey]\n",
    "            del summary_temp\n",
    "            del suppl_temp\n",
    "            summary_temp, suppl_temp = get_graph_measures(gcommon)\n",
    "            for dkey in summary_temp:\n",
    "                summary[dkey+\"_common\"] = summary_temp[dkey]\n",
    "            for dkey in suppl_temp:\n",
    "                suppl[dkey+\"_common\"] = suppl_temp[dkey]\n",
    "            del summary_temp\n",
    "            del suppl_temp\n",
    "            \n",
    "            print(\"intersection of top %d by in_degree vertices in different graphs\" % 50)\n",
    "            intersection_in_digree = set(suppl[\"top_in_degree_common\"]).intersection(set(suppl[\"top_in_degree_shares\"])).intersection(set(suppl[\"top_in_degree_likes\"])).intersection(set(suppl[\"top_in_degree_comments\"]))\n",
    "            summary[\"num_nodes_from_top100_indegree_in_each_collection\"] = len(intersection_in_digree)\n",
    "            \n",
    "            print(\"intersection of top %d by pagerank vertices in different graphs\" % 100)\n",
    "            intersection_pagerank = set(suppl[\"top_pagerank_common\"]).intersection(set(suppl[\"top_pagerank_shares\"])).intersection(set(suppl[\"top_pagerank_likes\"])).intersection(set(suppl[\"top_pagerank_comments\"]))\n",
    "            summary[\"num_nodes_from_top100_pagerank_in_each_collection\"] = len(intersection_pagerank)\n",
    "\n",
    "            suppl[\"max_cc_shares\"].save(upfolder_cmn_and_ccs+\"\\\\max_cc_sh_\"+period+(\"city_%s\" % city_str), format=\"csv\")\n",
    "            suppl[\"max_cc_likes\"].save(upfolder_cmn_and_ccs+\"\\\\max_cc_lk_\"+period+(\"city_%s\" % city_str), format=\"csv\")\n",
    "            suppl[\"max_cc_comments\"].save(upfolder_cmn_and_ccs+\"\\\\max_cc_cmt_\"+period+(\"city_%s\" % city_str), format=\"csv\")\n",
    "            suppl[\"max_cc_common\"].save(upfolder_cmn_and_ccs+\"\\\\max_cc_comn_\"+period+(\"city_%s\" % city_str), format=\"csv\")\n",
    "            \n",
    "            for v in summary:\n",
    "                summary[v] = [summary[v]]\n",
    "            sf = graphlab.SFrame(summary)\n",
    "            sf_main = sf_main.append(sf)\n",
    "            sf_main.save(summary_name)\n",
    "            sf_main.save(summary_name+\"_csv\", format=\"csv\")\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
